{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"kc_house_data.csv\")\n",
    "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "1      7242     2.0           0     0          3      7        2170   \n",
       "2     10000     1.0           0     0          3      6         770   \n",
       "3      5000     1.0           0     0          5      7        1050   \n",
       "4      8080     1.0           0     0          3      8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
    "pd.options.display.max_columns = 25\n",
    "# head 會顯示前五行的數據\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built           int64\n",
       "yr_renovated       int64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  year  month  day  \n",
       "0    98178  47.5112 -122.257           1340        5650  2014     10   13  \n",
       "1    98125  47.7210 -122.319           1690        7639  2014     12    9  \n",
       "2    98028  47.7379 -122.233           2720        8062  2015      2   25  \n",
       "3    98136  47.5208 -122.393           1360        5000  2014     12    9  \n",
       "4    98074  47.6168 -122.045           1800        7503  2015      2   18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將date日期拆為年、月和日並轉成數值\n",
    "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))\n",
    "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
    "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
    "\n",
    "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
    "data.drop(['id'], axis=\"columns\", inplace=True)\n",
    "data.drop(['date'], axis=\"columns\", inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_num = data.shape[0]\n",
    "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
    "indexes = np.random.permutation(data_num)\n",
    "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為6:2:2\n",
    "train_indexes = indexes[:int(data_num *0.6)]\n",
    "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
    "test_indexes = indexes[int(data_num *0.8):]\n",
    "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
    "train_data = data.loc[train_indexes]\n",
    "val_data = data.loc[val_indexes]\n",
    "test_data = data.loc[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = pd.concat([train_data, val_data])\n",
    "mean = train_validation_data.mean()\n",
    "std = train_validation_data.std()\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.array(train_data.drop('price', axis='columns'))\n",
    "y_train = np.array(train_data['price'])\n",
    "x_val = np.array(val_data.drop('price', axis='columns'))\n",
    "y_val = np.array(val_data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立一個Sequential型態的model\n",
    "model = keras.Sequential(name='model-1')\n",
    "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "# 第2層全連接層設為64個unit\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 最後一層全連接層設為1個unit\n",
    "model.add(layers.Dense(1))\n",
    "# 顯示網路模型架構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'lab2-logs/models/'\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
    "log_dir = os.path.join('lab2-logs', 'model-1')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# ModelCheckpoint回調函數幫忙儲存網路模型，可以設定只儲存最好的模型，「monitor」表示被監測的數據，「mode」min則代表監測數據越小越好。\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-1.h5', \n",
    "                                        monitor='val_mean_absolute_error', \n",
    "                                        save_best_only=True, \n",
    "                                        mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "203/203 [==============================] - 2s 8ms/step - loss: 0.5314 - mean_absolute_error: 0.4295 - val_loss: 0.2545 - val_mean_absolute_error: 0.3037\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1944 - mean_absolute_error: 0.2766 - val_loss: 0.2139 - val_mean_absolute_error: 0.2881\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1950 - mean_absolute_error: 0.2765 - val_loss: 0.1912 - val_mean_absolute_error: 0.2632\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1524 - mean_absolute_error: 0.2464 - val_loss: 0.1811 - val_mean_absolute_error: 0.2555\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1413 - mean_absolute_error: 0.2365 - val_loss: 0.1854 - val_mean_absolute_error: 0.2552\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1342 - mean_absolute_error: 0.2270 - val_loss: 0.1840 - val_mean_absolute_error: 0.2575\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1262 - mean_absolute_error: 0.2205 - val_loss: 0.1547 - val_mean_absolute_error: 0.2319\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1124 - mean_absolute_error: 0.2098 - val_loss: 0.1517 - val_mean_absolute_error: 0.2254\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1099 - mean_absolute_error: 0.2069 - val_loss: 0.1547 - val_mean_absolute_error: 0.2317\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1112 - mean_absolute_error: 0.2091 - val_loss: 0.1489 - val_mean_absolute_error: 0.2198\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0954 - mean_absolute_error: 0.1964 - val_loss: 0.1501 - val_mean_absolute_error: 0.2216\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0964 - mean_absolute_error: 0.1971 - val_loss: 0.1400 - val_mean_absolute_error: 0.2142\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0916 - mean_absolute_error: 0.1935 - val_loss: 0.1501 - val_mean_absolute_error: 0.2170\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0836 - mean_absolute_error: 0.1877 - val_loss: 0.1589 - val_mean_absolute_error: 0.2177\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0906 - mean_absolute_error: 0.1966 - val_loss: 0.1416 - val_mean_absolute_error: 0.2135\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0807 - mean_absolute_error: 0.1847 - val_loss: 0.1389 - val_mean_absolute_error: 0.2184\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0807 - mean_absolute_error: 0.1858 - val_loss: 0.1373 - val_mean_absolute_error: 0.2122\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0802 - mean_absolute_error: 0.1839 - val_loss: 0.1362 - val_mean_absolute_error: 0.2129\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0792 - mean_absolute_error: 0.1833 - val_loss: 0.1347 - val_mean_absolute_error: 0.2098\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0781 - mean_absolute_error: 0.1805 - val_loss: 0.1417 - val_mean_absolute_error: 0.2210\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0765 - mean_absolute_error: 0.1804 - val_loss: 0.1360 - val_mean_absolute_error: 0.2114\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0718 - mean_absolute_error: 0.1780 - val_loss: 0.1310 - val_mean_absolute_error: 0.2124\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.1766 - val_loss: 0.1357 - val_mean_absolute_error: 0.2108\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0710 - mean_absolute_error: 0.1748 - val_loss: 0.1268 - val_mean_absolute_error: 0.2058\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0657 - mean_absolute_error: 0.1714 - val_loss: 0.1353 - val_mean_absolute_error: 0.2108\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0654 - mean_absolute_error: 0.1712 - val_loss: 0.1389 - val_mean_absolute_error: 0.2184\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0687 - mean_absolute_error: 0.1739 - val_loss: 0.1287 - val_mean_absolute_error: 0.2076\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0662 - mean_absolute_error: 0.1723 - val_loss: 0.1581 - val_mean_absolute_error: 0.2194\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0717 - mean_absolute_error: 0.1762 - val_loss: 0.1332 - val_mean_absolute_error: 0.2074\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0652 - mean_absolute_error: 0.1714 - val_loss: 0.1403 - val_mean_absolute_error: 0.2112\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0617 - mean_absolute_error: 0.1683 - val_loss: 0.1267 - val_mean_absolute_error: 0.2044\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0614 - mean_absolute_error: 0.1653 - val_loss: 0.1317 - val_mean_absolute_error: 0.2083\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0618 - mean_absolute_error: 0.1669 - val_loss: 0.1281 - val_mean_absolute_error: 0.2102\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0614 - mean_absolute_error: 0.1669 - val_loss: 0.1389 - val_mean_absolute_error: 0.2184\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0639 - mean_absolute_error: 0.1668 - val_loss: 0.1326 - val_mean_absolute_error: 0.2108\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0600 - mean_absolute_error: 0.1647 - val_loss: 0.1362 - val_mean_absolute_error: 0.2113\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0619 - mean_absolute_error: 0.1654 - val_loss: 0.1315 - val_mean_absolute_error: 0.2146\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0627 - mean_absolute_error: 0.1677 - val_loss: 0.1266 - val_mean_absolute_error: 0.2071\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0568 - mean_absolute_error: 0.1612 - val_loss: 0.1270 - val_mean_absolute_error: 0.2081\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0569 - mean_absolute_error: 0.1604 - val_loss: 0.1310 - val_mean_absolute_error: 0.2074\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0571 - mean_absolute_error: 0.1617 - val_loss: 0.1315 - val_mean_absolute_error: 0.2069\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0555 - mean_absolute_error: 0.1619 - val_loss: 0.1309 - val_mean_absolute_error: 0.2060\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0542 - mean_absolute_error: 0.1586 - val_loss: 0.1267 - val_mean_absolute_error: 0.2098\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0564 - mean_absolute_error: 0.1602 - val_loss: 0.1268 - val_mean_absolute_error: 0.2060\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0596 - mean_absolute_error: 0.1625 - val_loss: 0.1303 - val_mean_absolute_error: 0.2075\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0548 - mean_absolute_error: 0.1591 - val_loss: 0.1301 - val_mean_absolute_error: 0.2055\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0548 - mean_absolute_error: 0.1591 - val_loss: 0.1318 - val_mean_absolute_error: 0.2072\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0481 - mean_absolute_error: 0.1526 - val_loss: 0.1336 - val_mean_absolute_error: 0.2106\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0532 - mean_absolute_error: 0.1605 - val_loss: 0.1281 - val_mean_absolute_error: 0.2075\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0507 - mean_absolute_error: 0.1553 - val_loss: 0.1290 - val_mean_absolute_error: 0.2083\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.1568 - val_loss: 0.1347 - val_mean_absolute_error: 0.2139\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0539 - mean_absolute_error: 0.1580 - val_loss: 0.1330 - val_mean_absolute_error: 0.2129\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0541 - mean_absolute_error: 0.1573 - val_loss: 0.1269 - val_mean_absolute_error: 0.2063\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0508 - mean_absolute_error: 0.1546 - val_loss: 0.1374 - val_mean_absolute_error: 0.2076\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0510 - mean_absolute_error: 0.1538 - val_loss: 0.1314 - val_mean_absolute_error: 0.2104\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0495 - mean_absolute_error: 0.1551 - val_loss: 0.1320 - val_mean_absolute_error: 0.2109\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0506 - mean_absolute_error: 0.1551 - val_loss: 0.1352 - val_mean_absolute_error: 0.2109\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0496 - mean_absolute_error: 0.1534 - val_loss: 0.1335 - val_mean_absolute_error: 0.2116\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0495 - mean_absolute_error: 0.1534 - val_loss: 0.1378 - val_mean_absolute_error: 0.2142\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0493 - mean_absolute_error: 0.1556 - val_loss: 0.1275 - val_mean_absolute_error: 0.2095\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0505 - mean_absolute_error: 0.1532 - val_loss: 0.1293 - val_mean_absolute_error: 0.2086\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0469 - mean_absolute_error: 0.1487 - val_loss: 0.1298 - val_mean_absolute_error: 0.2093\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0475 - mean_absolute_error: 0.1496 - val_loss: 0.1344 - val_mean_absolute_error: 0.2086\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0500 - mean_absolute_error: 0.1522 - val_loss: 0.1357 - val_mean_absolute_error: 0.2099\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0496 - mean_absolute_error: 0.1528 - val_loss: 0.1344 - val_mean_absolute_error: 0.2091\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0460 - mean_absolute_error: 0.1503 - val_loss: 0.1331 - val_mean_absolute_error: 0.2100\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0476 - mean_absolute_error: 0.1511 - val_loss: 0.1399 - val_mean_absolute_error: 0.2147\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0496 - mean_absolute_error: 0.1527 - val_loss: 0.1345 - val_mean_absolute_error: 0.2140\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0477 - mean_absolute_error: 0.1521 - val_loss: 0.1368 - val_mean_absolute_error: 0.2122\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0453 - mean_absolute_error: 0.1467 - val_loss: 0.1354 - val_mean_absolute_error: 0.2163\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0431 - mean_absolute_error: 0.1451 - val_loss: 0.1392 - val_mean_absolute_error: 0.2122\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0465 - mean_absolute_error: 0.1501 - val_loss: 0.1408 - val_mean_absolute_error: 0.2145\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0448 - mean_absolute_error: 0.1480 - val_loss: 0.1399 - val_mean_absolute_error: 0.2131\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0474 - mean_absolute_error: 0.1518 - val_loss: 0.1397 - val_mean_absolute_error: 0.2118\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0422 - mean_absolute_error: 0.1450 - val_loss: 0.1391 - val_mean_absolute_error: 0.2168\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0464 - mean_absolute_error: 0.1509 - val_loss: 0.1388 - val_mean_absolute_error: 0.2113\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0431 - mean_absolute_error: 0.1453 - val_loss: 0.1323 - val_mean_absolute_error: 0.2094\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0423 - mean_absolute_error: 0.1458 - val_loss: 0.1319 - val_mean_absolute_error: 0.2126\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0429 - mean_absolute_error: 0.1461 - val_loss: 0.1367 - val_mean_absolute_error: 0.2153\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0472 - mean_absolute_error: 0.1504 - val_loss: 0.1348 - val_mean_absolute_error: 0.2106\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0427 - mean_absolute_error: 0.1467 - val_loss: 0.1393 - val_mean_absolute_error: 0.2141\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0404 - mean_absolute_error: 0.1428 - val_loss: 0.1358 - val_mean_absolute_error: 0.2144\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0440 - mean_absolute_error: 0.1471 - val_loss: 0.1372 - val_mean_absolute_error: 0.2143\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0466 - mean_absolute_error: 0.1490 - val_loss: 0.1400 - val_mean_absolute_error: 0.2161\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0497 - mean_absolute_error: 0.1539 - val_loss: 0.1397 - val_mean_absolute_error: 0.2143\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0405 - mean_absolute_error: 0.1431 - val_loss: 0.1333 - val_mean_absolute_error: 0.2106\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0430 - mean_absolute_error: 0.1464 - val_loss: 0.1421 - val_mean_absolute_error: 0.2188\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0460 - mean_absolute_error: 0.1480 - val_loss: 0.1332 - val_mean_absolute_error: 0.2095\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0402 - mean_absolute_error: 0.1395 - val_loss: 0.1366 - val_mean_absolute_error: 0.2132\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0430 - mean_absolute_error: 0.1456 - val_loss: 0.1376 - val_mean_absolute_error: 0.2138\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1413 - val_loss: 0.1401 - val_mean_absolute_error: 0.2137\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0396 - mean_absolute_error: 0.1417 - val_loss: 0.1368 - val_mean_absolute_error: 0.2125\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1376 - val_loss: 0.1419 - val_mean_absolute_error: 0.2140\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.0396 - mean_absolute_error: 0.1418 - val_loss: 0.1345 - val_mean_absolute_error: 0.2113\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0395 - mean_absolute_error: 0.1404 - val_loss: 0.1384 - val_mean_absolute_error: 0.2145\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0424 - mean_absolute_error: 0.1455 - val_loss: 0.1385 - val_mean_absolute_error: 0.2119\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0394 - mean_absolute_error: 0.1400 - val_loss: 0.1391 - val_mean_absolute_error: 0.2129\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0399 - mean_absolute_error: 0.1413 - val_loss: 0.1408 - val_mean_absolute_error: 0.2143\n",
      "Epoch 99/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0414 - mean_absolute_error: 0.1433 - val_loss: 0.1348 - val_mean_absolute_error: 0.2145\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0368 - mean_absolute_error: 0.1382 - val_loss: 0.1387 - val_mean_absolute_error: 0.2137\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0382 - mean_absolute_error: 0.1397 - val_loss: 0.1412 - val_mean_absolute_error: 0.2164\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0381 - mean_absolute_error: 0.1389 - val_loss: 0.1469 - val_mean_absolute_error: 0.2224\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0384 - mean_absolute_error: 0.1402 - val_loss: 0.1425 - val_mean_absolute_error: 0.2166\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0378 - mean_absolute_error: 0.1414 - val_loss: 0.1415 - val_mean_absolute_error: 0.2169\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0409 - mean_absolute_error: 0.1436 - val_loss: 0.1451 - val_mean_absolute_error: 0.2171\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0362 - mean_absolute_error: 0.1368 - val_loss: 0.1375 - val_mean_absolute_error: 0.2130\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0380 - mean_absolute_error: 0.1387 - val_loss: 0.1421 - val_mean_absolute_error: 0.2179\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0368 - mean_absolute_error: 0.1386 - val_loss: 0.1476 - val_mean_absolute_error: 0.2235\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0400 - mean_absolute_error: 0.1436 - val_loss: 0.1458 - val_mean_absolute_error: 0.2157\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0400 - mean_absolute_error: 0.1401 - val_loss: 0.1438 - val_mean_absolute_error: 0.2196\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0367 - mean_absolute_error: 0.1378 - val_loss: 0.1429 - val_mean_absolute_error: 0.2143\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0385 - mean_absolute_error: 0.1391 - val_loss: 0.1444 - val_mean_absolute_error: 0.2189\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0443 - mean_absolute_error: 0.1469 - val_loss: 0.1441 - val_mean_absolute_error: 0.2167\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0354 - mean_absolute_error: 0.1351 - val_loss: 0.1445 - val_mean_absolute_error: 0.2175\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0371 - mean_absolute_error: 0.1374 - val_loss: 0.1427 - val_mean_absolute_error: 0.2157\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0359 - mean_absolute_error: 0.1357 - val_loss: 0.1404 - val_mean_absolute_error: 0.2159\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0368 - mean_absolute_error: 0.1367 - val_loss: 0.1476 - val_mean_absolute_error: 0.2200\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0381 - mean_absolute_error: 0.1396 - val_loss: 0.1407 - val_mean_absolute_error: 0.2161\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0408 - mean_absolute_error: 0.1420 - val_loss: 0.1462 - val_mean_absolute_error: 0.2173\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0365 - mean_absolute_error: 0.1357 - val_loss: 0.1455 - val_mean_absolute_error: 0.2192\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0353 - mean_absolute_error: 0.1350 - val_loss: 0.1592 - val_mean_absolute_error: 0.2245\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_absolute_error: 0.1359 - val_loss: 0.1488 - val_mean_absolute_error: 0.2173\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_absolute_error: 0.1374 - val_loss: 0.1454 - val_mean_absolute_error: 0.2178\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0350 - mean_absolute_error: 0.1355 - val_loss: 0.1470 - val_mean_absolute_error: 0.2182\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0337 - mean_absolute_error: 0.1334 - val_loss: 0.1498 - val_mean_absolute_error: 0.2195\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0350 - mean_absolute_error: 0.1343 - val_loss: 0.1480 - val_mean_absolute_error: 0.2184\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0343 - mean_absolute_error: 0.1335 - val_loss: 0.1494 - val_mean_absolute_error: 0.2201\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0345 - mean_absolute_error: 0.1346 - val_loss: 0.1510 - val_mean_absolute_error: 0.2214\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0339 - mean_absolute_error: 0.1339 - val_loss: 0.1495 - val_mean_absolute_error: 0.2209\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0340 - mean_absolute_error: 0.1340 - val_loss: 0.1478 - val_mean_absolute_error: 0.2186\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0326 - mean_absolute_error: 0.1313 - val_loss: 0.1520 - val_mean_absolute_error: 0.2224\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0330 - mean_absolute_error: 0.1325 - val_loss: 0.1516 - val_mean_absolute_error: 0.2226\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0439 - mean_absolute_error: 0.1463 - val_loss: 0.1462 - val_mean_absolute_error: 0.2208\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0362 - mean_absolute_error: 0.1355 - val_loss: 0.1440 - val_mean_absolute_error: 0.2200\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0334 - mean_absolute_error: 0.1321 - val_loss: 0.1502 - val_mean_absolute_error: 0.2193\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0319 - mean_absolute_error: 0.1300 - val_loss: 0.1466 - val_mean_absolute_error: 0.2200\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1292 - val_loss: 0.1478 - val_mean_absolute_error: 0.2206\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0329 - mean_absolute_error: 0.1304 - val_loss: 0.1475 - val_mean_absolute_error: 0.2172\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0345 - mean_absolute_error: 0.1346 - val_loss: 0.1441 - val_mean_absolute_error: 0.2167\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0354 - mean_absolute_error: 0.1356 - val_loss: 0.1463 - val_mean_absolute_error: 0.2200\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0328 - mean_absolute_error: 0.1316 - val_loss: 0.1465 - val_mean_absolute_error: 0.2224\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0382 - mean_absolute_error: 0.1379 - val_loss: 0.1486 - val_mean_absolute_error: 0.2242\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0323 - mean_absolute_error: 0.1310 - val_loss: 0.1451 - val_mean_absolute_error: 0.2192\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_absolute_error: 0.1342 - val_loss: 0.1446 - val_mean_absolute_error: 0.2176\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0324 - mean_absolute_error: 0.1306 - val_loss: 0.1460 - val_mean_absolute_error: 0.2198\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0372 - mean_absolute_error: 0.1369 - val_loss: 0.1508 - val_mean_absolute_error: 0.2197\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0323 - mean_absolute_error: 0.1310 - val_loss: 0.1471 - val_mean_absolute_error: 0.2202\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0323 - mean_absolute_error: 0.1319 - val_loss: 0.1507 - val_mean_absolute_error: 0.2220\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0332 - mean_absolute_error: 0.1323 - val_loss: 0.1523 - val_mean_absolute_error: 0.2228\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0343 - mean_absolute_error: 0.1327 - val_loss: 0.1472 - val_mean_absolute_error: 0.2230\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0308 - mean_absolute_error: 0.1287 - val_loss: 0.1519 - val_mean_absolute_error: 0.2251\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0338 - mean_absolute_error: 0.1339 - val_loss: 0.1538 - val_mean_absolute_error: 0.2224\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1294 - val_loss: 0.1558 - val_mean_absolute_error: 0.2301\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0327 - mean_absolute_error: 0.1318 - val_loss: 0.1508 - val_mean_absolute_error: 0.2320\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1308 - val_loss: 0.1452 - val_mean_absolute_error: 0.2199\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0327 - mean_absolute_error: 0.1321 - val_loss: 0.1474 - val_mean_absolute_error: 0.2201\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0302 - mean_absolute_error: 0.1277 - val_loss: 0.1545 - val_mean_absolute_error: 0.2226\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0337 - mean_absolute_error: 0.1333 - val_loss: 0.1475 - val_mean_absolute_error: 0.2202\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1302 - val_loss: 0.1518 - val_mean_absolute_error: 0.2234\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0332 - mean_absolute_error: 0.1326 - val_loss: 0.1460 - val_mean_absolute_error: 0.2213\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0309 - mean_absolute_error: 0.1284 - val_loss: 0.1456 - val_mean_absolute_error: 0.2192\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0341 - mean_absolute_error: 0.1317 - val_loss: 0.1587 - val_mean_absolute_error: 0.2236\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0317 - mean_absolute_error: 0.1301 - val_loss: 0.1527 - val_mean_absolute_error: 0.2203\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0315 - mean_absolute_error: 0.1285 - val_loss: 0.1519 - val_mean_absolute_error: 0.2213\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0309 - mean_absolute_error: 0.1298 - val_loss: 0.1483 - val_mean_absolute_error: 0.2197\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0307 - mean_absolute_error: 0.1283 - val_loss: 0.1495 - val_mean_absolute_error: 0.2223\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0310 - mean_absolute_error: 0.1284 - val_loss: 0.1533 - val_mean_absolute_error: 0.2231\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0319 - mean_absolute_error: 0.1299 - val_loss: 0.1496 - val_mean_absolute_error: 0.2216\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0307 - mean_absolute_error: 0.1293 - val_loss: 0.1534 - val_mean_absolute_error: 0.2236\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0293 - mean_absolute_error: 0.1261 - val_loss: 0.1512 - val_mean_absolute_error: 0.2238\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0316 - mean_absolute_error: 0.1297 - val_loss: 0.1477 - val_mean_absolute_error: 0.2222\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0301 - mean_absolute_error: 0.1276 - val_loss: 0.1533 - val_mean_absolute_error: 0.2266\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0322 - mean_absolute_error: 0.1317 - val_loss: 0.1451 - val_mean_absolute_error: 0.2199\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0313 - mean_absolute_error: 0.1278 - val_loss: 0.1462 - val_mean_absolute_error: 0.2239\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0291 - mean_absolute_error: 0.1253 - val_loss: 0.1555 - val_mean_absolute_error: 0.2312\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0353 - mean_absolute_error: 0.1356 - val_loss: 0.1513 - val_mean_absolute_error: 0.2210\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0296 - mean_absolute_error: 0.1268 - val_loss: 0.1533 - val_mean_absolute_error: 0.2228\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0301 - mean_absolute_error: 0.1290 - val_loss: 0.1554 - val_mean_absolute_error: 0.2258\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0298 - mean_absolute_error: 0.1272 - val_loss: 0.1510 - val_mean_absolute_error: 0.2227\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0274 - mean_absolute_error: 0.1232 - val_loss: 0.1522 - val_mean_absolute_error: 0.2217\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0300 - mean_absolute_error: 0.1269 - val_loss: 0.1513 - val_mean_absolute_error: 0.2249\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0315 - mean_absolute_error: 0.1299 - val_loss: 0.1551 - val_mean_absolute_error: 0.2249\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0297 - mean_absolute_error: 0.1271 - val_loss: 0.1561 - val_mean_absolute_error: 0.2256\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0350 - mean_absolute_error: 0.1333 - val_loss: 0.1462 - val_mean_absolute_error: 0.2234\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0319 - mean_absolute_error: 0.1293 - val_loss: 0.1516 - val_mean_absolute_error: 0.2265\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0334 - mean_absolute_error: 0.1309 - val_loss: 0.1519 - val_mean_absolute_error: 0.2256\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0300 - mean_absolute_error: 0.1271 - val_loss: 0.1517 - val_mean_absolute_error: 0.2223\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0279 - mean_absolute_error: 0.1236 - val_loss: 0.1579 - val_mean_absolute_error: 0.2230\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0456 - mean_absolute_error: 0.1409 - val_loss: 0.1473 - val_mean_absolute_error: 0.2196\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0292 - mean_absolute_error: 0.1252 - val_loss: 0.1507 - val_mean_absolute_error: 0.2226\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0283 - mean_absolute_error: 0.1235 - val_loss: 0.1509 - val_mean_absolute_error: 0.2213\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1215 - val_loss: 0.1532 - val_mean_absolute_error: 0.2236\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0281 - mean_absolute_error: 0.1239 - val_loss: 0.1507 - val_mean_absolute_error: 0.2236\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0281 - mean_absolute_error: 0.1232 - val_loss: 0.1516 - val_mean_absolute_error: 0.2268\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1216 - val_loss: 0.1488 - val_mean_absolute_error: 0.2204\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0278 - mean_absolute_error: 0.1230 - val_loss: 0.1512 - val_mean_absolute_error: 0.2202\n",
      "Epoch 197/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0323 - mean_absolute_error: 0.1294 - val_loss: 0.1497 - val_mean_absolute_error: 0.2218\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0311 - mean_absolute_error: 0.1277 - val_loss: 0.1525 - val_mean_absolute_error: 0.2232\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0301 - mean_absolute_error: 0.1271 - val_loss: 0.1526 - val_mean_absolute_error: 0.2233\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0281 - mean_absolute_error: 0.1245 - val_loss: 0.1556 - val_mean_absolute_error: 0.2253\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0281 - mean_absolute_error: 0.1247 - val_loss: 0.1564 - val_mean_absolute_error: 0.2288\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0293 - mean_absolute_error: 0.1265 - val_loss: 0.1539 - val_mean_absolute_error: 0.2227\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0277 - mean_absolute_error: 0.1230 - val_loss: 0.1538 - val_mean_absolute_error: 0.2264\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.1262 - val_loss: 0.1638 - val_mean_absolute_error: 0.2311\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0296 - mean_absolute_error: 0.1273 - val_loss: 0.1502 - val_mean_absolute_error: 0.2219\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0274 - mean_absolute_error: 0.1221 - val_loss: 0.1532 - val_mean_absolute_error: 0.2236\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0268 - mean_absolute_error: 0.1215 - val_loss: 0.1508 - val_mean_absolute_error: 0.2230\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0269 - mean_absolute_error: 0.1216 - val_loss: 0.1590 - val_mean_absolute_error: 0.2239\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.1242 - val_loss: 0.1564 - val_mean_absolute_error: 0.2233\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0289 - mean_absolute_error: 0.1241 - val_loss: 0.1548 - val_mean_absolute_error: 0.2232\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1223 - val_loss: 0.1552 - val_mean_absolute_error: 0.2246\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0283 - mean_absolute_error: 0.1239 - val_loss: 0.1597 - val_mean_absolute_error: 0.2276\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0284 - mean_absolute_error: 0.1237 - val_loss: 0.1551 - val_mean_absolute_error: 0.2249\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0275 - mean_absolute_error: 0.1244 - val_loss: 0.1521 - val_mean_absolute_error: 0.2271\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0274 - mean_absolute_error: 0.1222 - val_loss: 0.1541 - val_mean_absolute_error: 0.2232\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0255 - mean_absolute_error: 0.1184 - val_loss: 0.1558 - val_mean_absolute_error: 0.2266\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0292 - mean_absolute_error: 0.1253 - val_loss: 0.1550 - val_mean_absolute_error: 0.2255\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0287 - mean_absolute_error: 0.1247 - val_loss: 0.1633 - val_mean_absolute_error: 0.2298\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0323 - mean_absolute_error: 0.1301 - val_loss: 0.1543 - val_mean_absolute_error: 0.2248\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0287 - mean_absolute_error: 0.1250 - val_loss: 0.1520 - val_mean_absolute_error: 0.2236\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0252 - mean_absolute_error: 0.1182 - val_loss: 0.1581 - val_mean_absolute_error: 0.2254\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0320 - mean_absolute_error: 0.1285 - val_loss: 0.1601 - val_mean_absolute_error: 0.2290\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1225 - val_loss: 0.1548 - val_mean_absolute_error: 0.2249\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1235 - val_loss: 0.1560 - val_mean_absolute_error: 0.2245\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0262 - mean_absolute_error: 0.1208 - val_loss: 0.1579 - val_mean_absolute_error: 0.2261\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0275 - mean_absolute_error: 0.1221 - val_loss: 0.1524 - val_mean_absolute_error: 0.2245\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.1234 - val_loss: 0.1563 - val_mean_absolute_error: 0.2259\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1272 - val_loss: 0.1566 - val_mean_absolute_error: 0.2288\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0291 - mean_absolute_error: 0.1248 - val_loss: 0.1532 - val_mean_absolute_error: 0.2284\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1226 - val_loss: 0.1551 - val_mean_absolute_error: 0.2260\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0267 - mean_absolute_error: 0.1222 - val_loss: 0.1519 - val_mean_absolute_error: 0.2259\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0260 - mean_absolute_error: 0.1199 - val_loss: 0.1530 - val_mean_absolute_error: 0.2241\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0270 - mean_absolute_error: 0.1214 - val_loss: 0.1546 - val_mean_absolute_error: 0.2302\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0288 - mean_absolute_error: 0.1244 - val_loss: 0.1669 - val_mean_absolute_error: 0.2300\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0290 - mean_absolute_error: 0.1260 - val_loss: 0.1529 - val_mean_absolute_error: 0.2279\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0285 - mean_absolute_error: 0.1239 - val_loss: 0.1575 - val_mean_absolute_error: 0.2288\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0247 - mean_absolute_error: 0.1182 - val_loss: 0.1582 - val_mean_absolute_error: 0.2275\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0262 - mean_absolute_error: 0.1200 - val_loss: 0.1544 - val_mean_absolute_error: 0.2268\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1222 - val_loss: 0.1593 - val_mean_absolute_error: 0.2264\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0265 - mean_absolute_error: 0.1202 - val_loss: 0.1607 - val_mean_absolute_error: 0.2306\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.1275 - val_loss: 0.1604 - val_mean_absolute_error: 0.2257\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0278 - mean_absolute_error: 0.1227 - val_loss: 0.1648 - val_mean_absolute_error: 0.2295\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1217 - val_loss: 0.1559 - val_mean_absolute_error: 0.2280\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0263 - mean_absolute_error: 0.1208 - val_loss: 0.1592 - val_mean_absolute_error: 0.2274\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0255 - mean_absolute_error: 0.1187 - val_loss: 0.1568 - val_mean_absolute_error: 0.2260\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0256 - mean_absolute_error: 0.1192 - val_loss: 0.1561 - val_mean_absolute_error: 0.2269\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1217 - val_loss: 0.1574 - val_mean_absolute_error: 0.2269\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0276 - mean_absolute_error: 0.1222 - val_loss: 0.1549 - val_mean_absolute_error: 0.2248\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0252 - mean_absolute_error: 0.1191 - val_loss: 0.1605 - val_mean_absolute_error: 0.2289\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1206 - val_loss: 0.1598 - val_mean_absolute_error: 0.2288\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0276 - mean_absolute_error: 0.1227 - val_loss: 0.1583 - val_mean_absolute_error: 0.2299\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0282 - mean_absolute_error: 0.1224 - val_loss: 0.1620 - val_mean_absolute_error: 0.2289\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0280 - mean_absolute_error: 0.1227 - val_loss: 0.1550 - val_mean_absolute_error: 0.2314\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0274 - mean_absolute_error: 0.1212 - val_loss: 0.1568 - val_mean_absolute_error: 0.2246\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0259 - mean_absolute_error: 0.1192 - val_loss: 0.1632 - val_mean_absolute_error: 0.2352\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0331 - mean_absolute_error: 0.1313 - val_loss: 0.1604 - val_mean_absolute_error: 0.2280\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.1204 - val_loss: 0.1587 - val_mean_absolute_error: 0.2273\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0278 - mean_absolute_error: 0.1221 - val_loss: 0.1525 - val_mean_absolute_error: 0.2245\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0252 - mean_absolute_error: 0.1182 - val_loss: 0.1557 - val_mean_absolute_error: 0.2252\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0250 - mean_absolute_error: 0.1180 - val_loss: 0.1590 - val_mean_absolute_error: 0.2286\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0247 - mean_absolute_error: 0.1171 - val_loss: 0.1559 - val_mean_absolute_error: 0.2242\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0232 - mean_absolute_error: 0.1137 - val_loss: 0.1557 - val_mean_absolute_error: 0.2277\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0263 - mean_absolute_error: 0.1201 - val_loss: 0.1609 - val_mean_absolute_error: 0.2274\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0264 - mean_absolute_error: 0.1211 - val_loss: 0.1571 - val_mean_absolute_error: 0.2293\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0256 - mean_absolute_error: 0.1197 - val_loss: 0.1578 - val_mean_absolute_error: 0.2286\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0246 - mean_absolute_error: 0.1165 - val_loss: 0.1562 - val_mean_absolute_error: 0.2309\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0319 - mean_absolute_error: 0.1285 - val_loss: 0.1549 - val_mean_absolute_error: 0.2295\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0255 - mean_absolute_error: 0.1193 - val_loss: 0.1588 - val_mean_absolute_error: 0.2269\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0257 - mean_absolute_error: 0.1190 - val_loss: 0.1595 - val_mean_absolute_error: 0.2284\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0241 - mean_absolute_error: 0.1169 - val_loss: 0.1602 - val_mean_absolute_error: 0.2277\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0271 - mean_absolute_error: 0.1217 - val_loss: 0.1530 - val_mean_absolute_error: 0.2282\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0244 - mean_absolute_error: 0.1182 - val_loss: 0.1560 - val_mean_absolute_error: 0.2276\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0246 - mean_absolute_error: 0.1166 - val_loss: 0.1577 - val_mean_absolute_error: 0.2308\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0237 - mean_absolute_error: 0.1154 - val_loss: 0.1550 - val_mean_absolute_error: 0.2272\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0241 - mean_absolute_error: 0.1162 - val_loss: 0.1591 - val_mean_absolute_error: 0.2286\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0254 - mean_absolute_error: 0.1193 - val_loss: 0.1567 - val_mean_absolute_error: 0.2282\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0245 - mean_absolute_error: 0.1169 - val_loss: 0.1577 - val_mean_absolute_error: 0.2327\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0247 - mean_absolute_error: 0.1181 - val_loss: 0.1536 - val_mean_absolute_error: 0.2266\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0264 - mean_absolute_error: 0.1202 - val_loss: 0.1527 - val_mean_absolute_error: 0.2266\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0251 - mean_absolute_error: 0.1192 - val_loss: 0.1574 - val_mean_absolute_error: 0.2269\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0249 - mean_absolute_error: 0.1185 - val_loss: 0.1572 - val_mean_absolute_error: 0.2324\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0239 - mean_absolute_error: 0.1165 - val_loss: 0.1595 - val_mean_absolute_error: 0.2331\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0248 - mean_absolute_error: 0.1183 - val_loss: 0.1609 - val_mean_absolute_error: 0.2321\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0303 - mean_absolute_error: 0.1261 - val_loss: 0.1574 - val_mean_absolute_error: 0.2320\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0260 - mean_absolute_error: 0.1192 - val_loss: 0.1592 - val_mean_absolute_error: 0.2309\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0259 - mean_absolute_error: 0.1198 - val_loss: 0.1556 - val_mean_absolute_error: 0.2274\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0240 - mean_absolute_error: 0.1161 - val_loss: 0.1578 - val_mean_absolute_error: 0.2296\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0237 - mean_absolute_error: 0.1165 - val_loss: 0.1591 - val_mean_absolute_error: 0.2277\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0248 - mean_absolute_error: 0.1170 - val_loss: 0.1528 - val_mean_absolute_error: 0.2273\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0266 - mean_absolute_error: 0.1198 - val_loss: 0.1562 - val_mean_absolute_error: 0.2288\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0238 - mean_absolute_error: 0.1158 - val_loss: 0.1526 - val_mean_absolute_error: 0.2258\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0248 - mean_absolute_error: 0.1168 - val_loss: 0.1542 - val_mean_absolute_error: 0.2284\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0236 - mean_absolute_error: 0.1148 - val_loss: 0.1578 - val_mean_absolute_error: 0.2283\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0270 - mean_absolute_error: 0.1217 - val_loss: 0.1533 - val_mean_absolute_error: 0.2274\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0244 - mean_absolute_error: 0.1173 - val_loss: 0.1524 - val_mean_absolute_error: 0.2275\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0237 - mean_absolute_error: 0.1157 - val_loss: 0.1538 - val_mean_absolute_error: 0.2259\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0240 - mean_absolute_error: 0.1159 - val_loss: 0.1547 - val_mean_absolute_error: 0.2273\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0233 - mean_absolute_error: 0.1148 - val_loss: 0.1566 - val_mean_absolute_error: 0.2289\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0236 - mean_absolute_error: 0.1154 - val_loss: 0.1559 - val_mean_absolute_error: 0.2285\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0238 - mean_absolute_error: 0.1160 - val_loss: 0.1537 - val_mean_absolute_error: 0.2261\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,  # 傳入訓練數據\n",
    "               batch_size=64,  # 批次大小設為64\n",
    "               epochs=300,  # 整個dataset訓練300遍\n",
    "               validation_data=(x_val, y_val),  # 驗證數據\n",
    "               callbacks=[model_cbk, model_mckp])  # Tensorboard回調函數紀錄訓練過程，ModelCheckpoint回調函數儲存最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3ac5ee970>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label='train')\n",
    "plt.plot(history.history['val_loss'],label='validation')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1: 13.55%\n"
     ]
    }
   ],
   "source": [
    "model_1 = keras.models.load_model('lab2-logs/models/Best-model-1.h5')\n",
    "y_test=np.array(test_data['price'])\n",
    "test_data=(test_data-mean)/std\n",
    "x_test=np.array(test_data.drop('price',axis='columns'))\n",
    "\n",
    "y_pred = model_1.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_1: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
